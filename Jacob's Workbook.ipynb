{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>ac</th>\n",
       "      <th>ae</th>\n",
       "      <th>ad</th>\n",
       "      <th>af</th>\n",
       "      <th>aj</th>\n",
       "      <th>ah</th>\n",
       "      <th>ai</th>\n",
       "      <th>ak</th>\n",
       "      <th>...</th>\n",
       "      <th>rh</th>\n",
       "      <th>ri</th>\n",
       "      <th>rk</th>\n",
       "      <th>rl</th>\n",
       "      <th>rm</th>\n",
       "      <th>rn</th>\n",
       "      <th>ro</th>\n",
       "      <th>rp</th>\n",
       "      <th>rq</th>\n",
       "      <th>rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>782</td>\n",
       "      <td>253</td>\n",
       "      <td>60</td>\n",
       "      <td>414</td>\n",
       "      <td>972</td>\n",
       "      <td>297</td>\n",
       "      <td>471</td>\n",
       "      <td>609</td>\n",
       "      <td>835</td>\n",
       "      <td>...</td>\n",
       "      <td>417</td>\n",
       "      <td>373</td>\n",
       "      <td>364</td>\n",
       "      <td>930</td>\n",
       "      <td>95</td>\n",
       "      <td>967</td>\n",
       "      <td>770</td>\n",
       "      <td>542</td>\n",
       "      <td>26</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272</td>\n",
       "      <td>220</td>\n",
       "      <td>664</td>\n",
       "      <td>494</td>\n",
       "      <td>76</td>\n",
       "      <td>920</td>\n",
       "      <td>164</td>\n",
       "      <td>956</td>\n",
       "      <td>340</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>419</td>\n",
       "      <td>129</td>\n",
       "      <td>555</td>\n",
       "      <td>14</td>\n",
       "      <td>917</td>\n",
       "      <td>717</td>\n",
       "      <td>610</td>\n",
       "      <td>824</td>\n",
       "      <td>345</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa   ab   ac   ae   ad   af   aj   ah   ai   ak ...    rh   ri   rk   rl  \\\n",
       "0  125  782  253   60  414  972  297  471  609  835 ...   417  373  364  930   \n",
       "1  272  220  664  494   76  920  164  956  340   89 ...   419  129  555   14   \n",
       "\n",
       "    rm   rn   ro   rp   rq   rr  \n",
       "0   95  967  770  542   26  698  \n",
       "1  917  717  610  824  345  816  \n",
       "\n",
       "[2 rows x 289 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_csv('./data/out.csv', nrows=2)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa int64 <class 'int'>\n",
      "ab int64 <class 'int'>\n",
      "ac int64 <class 'int'>\n",
      "ae int64 <class 'int'>\n",
      "ad int64 <class 'int'>\n",
      "af int64 <class 'int'>\n",
      "aj int64 <class 'int'>\n",
      "ah int64 <class 'int'>\n",
      "ai int64 <class 'int'>\n",
      "ak int64 <class 'int'>\n",
      "al int64 <class 'int'>\n",
      "am int64 <class 'int'>\n",
      "an int64 <class 'int'>\n",
      "ao int64 <class 'int'>\n",
      "ap int64 <class 'int'>\n",
      "aq int64 <class 'int'>\n",
      "ar int64 <class 'int'>\n",
      "ba int64 <class 'int'>\n",
      "bb int64 <class 'int'>\n",
      "bc int64 <class 'int'>\n",
      "be int64 <class 'int'>\n",
      "bd int64 <class 'int'>\n",
      "bf int64 <class 'int'>\n",
      "bj int64 <class 'int'>\n",
      "bh int64 <class 'int'>\n",
      "bi int64 <class 'int'>\n",
      "bk int64 <class 'int'>\n",
      "bl int64 <class 'int'>\n",
      "bm int64 <class 'int'>\n",
      "bn int64 <class 'int'>\n",
      "bo int64 <class 'int'>\n",
      "bp int64 <class 'int'>\n",
      "bq int64 <class 'int'>\n",
      "br int64 <class 'int'>\n",
      "ca int64 <class 'int'>\n",
      "cb int64 <class 'int'>\n",
      "cc int64 <class 'int'>\n",
      "ce int64 <class 'int'>\n",
      "cd int64 <class 'int'>\n",
      "cf int64 <class 'int'>\n",
      "cj int64 <class 'int'>\n",
      "ch int64 <class 'int'>\n",
      "ci int64 <class 'int'>\n",
      "ck int64 <class 'int'>\n",
      "cl int64 <class 'int'>\n",
      "cm int64 <class 'int'>\n",
      "cn int64 <class 'int'>\n",
      "co int64 <class 'int'>\n",
      "cp int64 <class 'int'>\n",
      "cq int64 <class 'int'>\n",
      "cr int64 <class 'int'>\n",
      "ea int64 <class 'int'>\n",
      "eb int64 <class 'int'>\n",
      "ec int64 <class 'int'>\n",
      "ee int64 <class 'int'>\n",
      "ed int64 <class 'int'>\n",
      "ef int64 <class 'int'>\n",
      "ej int64 <class 'int'>\n",
      "eh int64 <class 'int'>\n",
      "ei int64 <class 'int'>\n",
      "ek int64 <class 'int'>\n",
      "el int64 <class 'int'>\n",
      "em int64 <class 'int'>\n",
      "en int64 <class 'int'>\n",
      "eo int64 <class 'int'>\n",
      "ep int64 <class 'int'>\n",
      "eq int64 <class 'int'>\n",
      "er int64 <class 'int'>\n",
      "da int64 <class 'int'>\n",
      "db int64 <class 'int'>\n",
      "dc int64 <class 'int'>\n",
      "de int64 <class 'int'>\n",
      "dd int64 <class 'int'>\n",
      "df int64 <class 'int'>\n",
      "dj int64 <class 'int'>\n",
      "dh int64 <class 'int'>\n",
      "di int64 <class 'int'>\n",
      "dk int64 <class 'int'>\n",
      "dl int64 <class 'int'>\n",
      "dm int64 <class 'int'>\n",
      "dn int64 <class 'int'>\n",
      "do int64 <class 'int'>\n",
      "dp int64 <class 'int'>\n",
      "dq int64 <class 'int'>\n",
      "dr int64 <class 'int'>\n",
      "fa int64 <class 'int'>\n",
      "fb int64 <class 'int'>\n",
      "fc int64 <class 'int'>\n",
      "fe int64 <class 'int'>\n",
      "fd int64 <class 'int'>\n",
      "ff int64 <class 'int'>\n",
      "fj int64 <class 'int'>\n",
      "fh int64 <class 'int'>\n",
      "fi int64 <class 'int'>\n",
      "fk int64 <class 'int'>\n",
      "fl int64 <class 'int'>\n",
      "fm int64 <class 'int'>\n",
      "fn int64 <class 'int'>\n",
      "fo int64 <class 'int'>\n",
      "fp int64 <class 'int'>\n",
      "fq int64 <class 'int'>\n",
      "fr int64 <class 'int'>\n",
      "ja int64 <class 'int'>\n",
      "jb int64 <class 'int'>\n",
      "jc int64 <class 'int'>\n",
      "je int64 <class 'int'>\n",
      "jd int64 <class 'int'>\n",
      "jf int64 <class 'int'>\n",
      "jj int64 <class 'int'>\n",
      "jh int64 <class 'int'>\n",
      "ji int64 <class 'int'>\n",
      "jk int64 <class 'int'>\n",
      "jl int64 <class 'int'>\n",
      "jm int64 <class 'int'>\n",
      "jn int64 <class 'int'>\n",
      "jo int64 <class 'int'>\n",
      "jp int64 <class 'int'>\n",
      "jq int64 <class 'int'>\n",
      "jr int64 <class 'int'>\n",
      "ha int64 <class 'int'>\n",
      "hb int64 <class 'int'>\n",
      "hc int64 <class 'int'>\n",
      "he int64 <class 'int'>\n",
      "hd int64 <class 'int'>\n",
      "hf int64 <class 'int'>\n",
      "hj int64 <class 'int'>\n",
      "hh int64 <class 'int'>\n",
      "hi int64 <class 'int'>\n",
      "hk int64 <class 'int'>\n",
      "hl int64 <class 'int'>\n",
      "hm int64 <class 'int'>\n",
      "hn int64 <class 'int'>\n",
      "ho int64 <class 'int'>\n",
      "hp int64 <class 'int'>\n",
      "hq int64 <class 'int'>\n",
      "hr int64 <class 'int'>\n",
      "ia int64 <class 'int'>\n",
      "ib int64 <class 'int'>\n",
      "ic int64 <class 'int'>\n",
      "ie int64 <class 'int'>\n",
      "id int64 <class 'int'>\n",
      "if int64 <class 'int'>\n",
      "ij int64 <class 'int'>\n",
      "ih int64 <class 'int'>\n",
      "ii int64 <class 'int'>\n",
      "ik int64 <class 'int'>\n",
      "il int64 <class 'int'>\n",
      "im int64 <class 'int'>\n",
      "in int64 <class 'int'>\n",
      "io int64 <class 'int'>\n",
      "ip int64 <class 'int'>\n",
      "iq int64 <class 'int'>\n",
      "ir int64 <class 'int'>\n",
      "ka int64 <class 'int'>\n",
      "kb int64 <class 'int'>\n",
      "kc int64 <class 'int'>\n",
      "ke int64 <class 'int'>\n",
      "kd int64 <class 'int'>\n",
      "kf int64 <class 'int'>\n",
      "kj int64 <class 'int'>\n",
      "kh int64 <class 'int'>\n",
      "ki int64 <class 'int'>\n",
      "kk int64 <class 'int'>\n",
      "kl int64 <class 'int'>\n",
      "km int64 <class 'int'>\n",
      "kn int64 <class 'int'>\n",
      "ko int64 <class 'int'>\n",
      "kp int64 <class 'int'>\n",
      "kq int64 <class 'int'>\n",
      "kr int64 <class 'int'>\n",
      "la int64 <class 'int'>\n",
      "lb int64 <class 'int'>\n",
      "lc int64 <class 'int'>\n",
      "le int64 <class 'int'>\n",
      "ld int64 <class 'int'>\n",
      "lf int64 <class 'int'>\n",
      "lj int64 <class 'int'>\n",
      "lh int64 <class 'int'>\n",
      "li int64 <class 'int'>\n",
      "lk int64 <class 'int'>\n",
      "ll int64 <class 'int'>\n",
      "lm int64 <class 'int'>\n",
      "ln int64 <class 'int'>\n",
      "lo int64 <class 'int'>\n",
      "lp int64 <class 'int'>\n",
      "lq int64 <class 'int'>\n",
      "lr int64 <class 'int'>\n",
      "ma int64 <class 'int'>\n",
      "mb int64 <class 'int'>\n",
      "mc int64 <class 'int'>\n",
      "me int64 <class 'int'>\n",
      "md int64 <class 'int'>\n",
      "mf int64 <class 'int'>\n",
      "mj int64 <class 'int'>\n",
      "mh int64 <class 'int'>\n",
      "mi int64 <class 'int'>\n",
      "mk int64 <class 'int'>\n",
      "ml int64 <class 'int'>\n",
      "mm int64 <class 'int'>\n",
      "mn int64 <class 'int'>\n",
      "mo int64 <class 'int'>\n",
      "mp int64 <class 'int'>\n",
      "mq int64 <class 'int'>\n",
      "mr int64 <class 'int'>\n",
      "na int64 <class 'int'>\n",
      "nb int64 <class 'int'>\n",
      "nc int64 <class 'int'>\n",
      "ne int64 <class 'int'>\n",
      "nd int64 <class 'int'>\n",
      "nf int64 <class 'int'>\n",
      "nj int64 <class 'int'>\n",
      "nh int64 <class 'int'>\n",
      "ni int64 <class 'int'>\n",
      "nk int64 <class 'int'>\n",
      "nl int64 <class 'int'>\n",
      "nm int64 <class 'int'>\n",
      "nn int64 <class 'int'>\n",
      "no int64 <class 'int'>\n",
      "np int64 <class 'int'>\n",
      "nq int64 <class 'int'>\n",
      "nr int64 <class 'int'>\n",
      "oa int64 <class 'int'>\n",
      "ob int64 <class 'int'>\n",
      "oc int64 <class 'int'>\n",
      "oe int64 <class 'int'>\n",
      "od int64 <class 'int'>\n",
      "of int64 <class 'int'>\n",
      "oj int64 <class 'int'>\n",
      "oh int64 <class 'int'>\n",
      "oi int64 <class 'int'>\n",
      "ok int64 <class 'int'>\n",
      "ol int64 <class 'int'>\n",
      "om int64 <class 'int'>\n",
      "on int64 <class 'int'>\n",
      "oo int64 <class 'int'>\n",
      "op int64 <class 'int'>\n",
      "oq int64 <class 'int'>\n",
      "or int64 <class 'int'>\n",
      "pa int64 <class 'int'>\n",
      "pb int64 <class 'int'>\n",
      "pc int64 <class 'int'>\n",
      "pe int64 <class 'int'>\n",
      "pd int64 <class 'int'>\n",
      "pf int64 <class 'int'>\n",
      "pj int64 <class 'int'>\n",
      "ph int64 <class 'int'>\n",
      "pi int64 <class 'int'>\n",
      "pk int64 <class 'int'>\n",
      "pl int64 <class 'int'>\n",
      "pm int64 <class 'int'>\n",
      "pn int64 <class 'int'>\n",
      "po int64 <class 'int'>\n",
      "pp int64 <class 'int'>\n",
      "pq int64 <class 'int'>\n",
      "pr int64 <class 'int'>\n",
      "qa int64 <class 'int'>\n",
      "qb int64 <class 'int'>\n",
      "qc int64 <class 'int'>\n",
      "qe int64 <class 'int'>\n",
      "qd int64 <class 'int'>\n",
      "qf int64 <class 'int'>\n",
      "qj int64 <class 'int'>\n",
      "qh int64 <class 'int'>\n",
      "qi int64 <class 'int'>\n",
      "qk int64 <class 'int'>\n",
      "ql int64 <class 'int'>\n",
      "qm int64 <class 'int'>\n",
      "qn int64 <class 'int'>\n",
      "qo int64 <class 'int'>\n",
      "qp int64 <class 'int'>\n",
      "qq int64 <class 'int'>\n",
      "qr int64 <class 'int'>\n",
      "ra int64 <class 'int'>\n",
      "rb int64 <class 'int'>\n",
      "rc int64 <class 'int'>\n",
      "re int64 <class 'int'>\n",
      "rd int64 <class 'int'>\n",
      "rf int64 <class 'int'>\n",
      "rj int64 <class 'int'>\n",
      "rh int64 <class 'int'>\n",
      "ri int64 <class 'int'>\n",
      "rk int64 <class 'int'>\n",
      "rl int64 <class 'int'>\n",
      "rm int64 <class 'int'>\n",
      "rn int64 <class 'int'>\n",
      "ro int64 <class 'int'>\n",
      "rp int64 <class 'int'>\n",
      "rq int64 <class 'int'>\n",
      "rr int64 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "def is_date(string):\n",
    "    try: \n",
    "        parse(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "for c in t:\n",
    "    dtype = t[c].dtype\n",
    "    if dtype == int:\n",
    "        print(c,dtype,int)\n",
    "    elif dtype == bool:\n",
    "        print(c,dtype,bool)\n",
    "    elif is_date(t[c][0]):\n",
    "        print(c,dtype,\"date\")\n",
    "    else:\n",
    "        print(c,dtype, str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa,ab,ac,ae,ad,af,aj,ah,ai,ak,al,am,an,ao,ap,aq,ar,ba,bb,bc,be,bd,bf,bj,bh,bi,bk,bl,bm,bn,bo,bp,bq,br,ca,cb,cc,ce,cd,cf,cj,ch,ci,ck,cl,cm,cn,co,cp,cq,cr,ea,eb,ec,ee,ed,ef,ej,eh,ei,ek,el,em,en,eo,ep,eq,er,da,db,dc,de,dd,df,dj,dh,di,dk,dl,dm,dn,do,dp,dq,dr,fa,fb,fc,fe,fd,ff,fj,fh,fi,fk,fl,fm,fn,fo,fp,fq,fr,ja,jb,jc,je,jd,jf,jj,jh,ji,jk,jl,jm,jn,jo,jp,jq,jr,ha,hb,hc,he,hd,hf,hj,hh,hi,hk,hl,hm,hn,ho,hp,hq,hr,ia,ib,ic,ie,id,if,ij,ih,ii,ik,il,im,in,io,ip,iq,ir,ka,kb,kc,ke,kd,kf,kj,kh,ki,kk,kl,km,kn,ko,kp,kq,kr,la,lb,lc,le,ld,lf,lj,lh,li,lk,ll,lm,ln,lo,lp,lq,lr,ma,mb,mc,me,md,mf,mj,mh,mi,mk,ml,mm,mn,mo,mp,mq,mr,na,nb,nc,ne,nd,nf,nj,nh,ni,nk,nl,nm,nn,no,np,nq,nr,oa,ob,oc,oe,od,of,oj,oh,oi,ok,ol,om,on,oo,op,oq,or,pa,pb,pc,pe,pd,pf,pj,ph,pi,pk,pl,pm,pn,po,pp,pq,pr,qa,qb,qc,qe,qd,qf,qj,qh,qi,qk,ql,qm,qn,qo,qp,qq,qr,ra,rb,rc,re,rd,rf,rj,rh,ri,rk,rl,rm,rn,ro,rp,rq,rr\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/out.csv'\n",
    "f = open(filename, 'r')\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa,ab,ac,ae,ad,af,aj,ah,ai,ak,al,am,an,ao,ap,aq,ar,ba,bb,bc,be,bd,bf,bj,bh,bi,bk,bl,bm,bn,bo,bp,bq,br,ca,cb,cc,ce,cd,cf,cj,ch,ci,ck,cl,cm,cn,co,cp,cq,cr,ea,eb,ec,ee,ed,ef,ej,eh,ei,ek,el,em,en,eo,ep,eq,er,da,db,dc,de,dd,df,dj,dh,di,dk,dl,dm,dn,do,dp,dq,dr,fa,fb,fc,fe,fd,ff,fj,fh,fi,fk,fl,fm,fn,fo,fp,fq,fr,ja,jb,jc,je,jd,jf,jj,jh,ji,jk,jl,jm,jn,jo,jp,jq,jr,ha,hb,hc,he,hd,hf,hj,hh,hi,hk,hl,hm,hn,ho,hp,hq,hr,ia,ib,ic,ie,id,if,ij,ih,ii,ik,il,im,in,io,ip,iq,ir,ka,kb,kc,ke,kd,kf,kj,kh,ki,kk,kl,km,kn,ko,kp,kq,kr,la,lb,lc,le,ld,lf,lj,lh,li,lk,ll,lm,ln,lo,lp,lq,lr,ma,mb,mc,me,md,mf,mj,mh,mi,mk,ml,mm,mn,mo,mp,mq,mr,na,nb,nc,ne,nd,nf,nj,nh,ni,nk,nl,nm,nn,no,np,nq,nr,oa,ob,oc,oe,od,of,oj,oh,oi,ok,ol,om,on,oo,op,oq,or,pa,pb,pc,pe,pd,pf,pj,ph,pi,pk,pl,pm,pn,po,pp,pq,pr,qa,qb,qc,qe,qd,qf,qj,qh,qi,qk,ql,qm,qn,qo,qp,qq,qr,ra,rb,rc,re,rd,rf,rj,rh,ri,rk,rl,rm,rn,ro,rp,rq,rr\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(0)\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125396785"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the end\n",
    "f.seek(0, os.SEEK_END)\n",
    "end = f.tell()\n",
    "\n",
    "# Start at the beginning\n",
    "f.seek(0)\n",
    "lines = [0]\n",
    "pos = 0\n",
    "while pos < end:\n",
    "    f.readline()\n",
    "    pos = f.tell()\n",
    "    lines.append(pos)\n",
    "f.tell()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>ac</th>\n",
       "      <th>ae</th>\n",
       "      <th>ad</th>\n",
       "      <th>af</th>\n",
       "      <th>aj</th>\n",
       "      <th>ah</th>\n",
       "      <th>ai</th>\n",
       "      <th>ak</th>\n",
       "      <th>...</th>\n",
       "      <th>rh</th>\n",
       "      <th>ri</th>\n",
       "      <th>rk</th>\n",
       "      <th>rl</th>\n",
       "      <th>rm</th>\n",
       "      <th>rn</th>\n",
       "      <th>ro</th>\n",
       "      <th>rp</th>\n",
       "      <th>rq</th>\n",
       "      <th>rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>782</td>\n",
       "      <td>253</td>\n",
       "      <td>60</td>\n",
       "      <td>414</td>\n",
       "      <td>972</td>\n",
       "      <td>297</td>\n",
       "      <td>471</td>\n",
       "      <td>609</td>\n",
       "      <td>835</td>\n",
       "      <td>...</td>\n",
       "      <td>417</td>\n",
       "      <td>373</td>\n",
       "      <td>364</td>\n",
       "      <td>930</td>\n",
       "      <td>95</td>\n",
       "      <td>967</td>\n",
       "      <td>770</td>\n",
       "      <td>542</td>\n",
       "      <td>26</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272</td>\n",
       "      <td>220</td>\n",
       "      <td>664</td>\n",
       "      <td>494</td>\n",
       "      <td>76</td>\n",
       "      <td>920</td>\n",
       "      <td>164</td>\n",
       "      <td>956</td>\n",
       "      <td>340</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>419</td>\n",
       "      <td>129</td>\n",
       "      <td>555</td>\n",
       "      <td>14</td>\n",
       "      <td>917</td>\n",
       "      <td>717</td>\n",
       "      <td>610</td>\n",
       "      <td>824</td>\n",
       "      <td>345</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>617</td>\n",
       "      <td>948</td>\n",
       "      <td>979</td>\n",
       "      <td>53</td>\n",
       "      <td>158</td>\n",
       "      <td>723</td>\n",
       "      <td>544</td>\n",
       "      <td>655</td>\n",
       "      <td>731</td>\n",
       "      <td>217</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>22</td>\n",
       "      <td>961</td>\n",
       "      <td>284</td>\n",
       "      <td>613</td>\n",
       "      <td>376</td>\n",
       "      <td>936</td>\n",
       "      <td>350</td>\n",
       "      <td>147</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>950</td>\n",
       "      <td>830</td>\n",
       "      <td>150</td>\n",
       "      <td>241</td>\n",
       "      <td>10</td>\n",
       "      <td>372</td>\n",
       "      <td>38</td>\n",
       "      <td>324</td>\n",
       "      <td>490</td>\n",
       "      <td>604</td>\n",
       "      <td>...</td>\n",
       "      <td>459</td>\n",
       "      <td>106</td>\n",
       "      <td>95</td>\n",
       "      <td>872</td>\n",
       "      <td>479</td>\n",
       "      <td>700</td>\n",
       "      <td>240</td>\n",
       "      <td>27</td>\n",
       "      <td>418</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa   ab   ac   ae   ad   af   aj   ah   ai   ak ...    rh   ri   rk   rl  \\\n",
       "0  125  782  253   60  414  972  297  471  609  835 ...   417  373  364  930   \n",
       "1  272  220  664  494   76  920  164  956  340   89 ...   419  129  555   14   \n",
       "2  617  948  979   53  158  723  544  655  731  217 ...   145   22  961  284   \n",
       "3  950  830  150  241   10  372   38  324  490  604 ...   459  106   95  872   \n",
       "\n",
       "    rm   rn   ro   rp   rq   rr  \n",
       "0   95  967  770  542   26  698  \n",
       "1  917  717  610  824  345  816  \n",
       "2  613  376  936  350  147  907  \n",
       "3  479  700  240   27  418  361  \n",
       "\n",
       "[4 rows x 289 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename, nrows=4)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 867, 1994, 3115]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'125,782,253,60,414,972,297,471,609,835,467,548,99,340,625,805,710,903,185,955,915,292,299,14,501,640,821,991,123,19,56,132,580,811,56,771,164,362,733,188,979,721,68,363,574,148,749,609,797,811,835,334,406,264,72,50,898,468,10,160,46,149,312,612,504,757,628,417,721,240,890,627,431,245,430,578,427,363,416,416,852,444,254,181,522,689,814,699,101,115,134,291,171,763,317,873,402,618,327,676,371,933,237,585,729,414,575,338,69,673,492,150,867,535,940,572,49,231,165,541,773,215,896,795,297,777,436,640,66,113,105,102,284,231,426,81,338,335,47,228,341,374,538,588,876,581,686,584,74,377,703,758,583,513,477,618,569,634,943,449,998,650,397,896,415,762,378,895,400,511,614,368,954,518,966,794,266,349,927,185,416,686,359,864,951,165,196,610,238,739,961,413,566,336,662,27,785,695,327,325,669,680,574,664,30,396,9,421,565,253,537,523,40,21,479,596,400,827,211,815,793,557,16,118,573,71,635,980,486,714,459,953,524,920,103,371,362,941,619,458,796,73,511,248,58,724,203,721,982,332,628,814,758,122,583,246,746,162,536,342,960,337,16,549,319,682,1000,711,155,392,313,798,258,750,668,290,691,452,433,417,373,364,930,95,967,770,542,26,698\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(lines[1])\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stolen from StackOverflow\n",
    "# https://stackoverflow.com/questions/14996453/python-libraries-to-calculate-human-readable-filesize-from-bytes\n",
    "suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n",
    "def humansize(nbytes):\n",
    "    i = 0\n",
    "    while nbytes >= 1024 and i < len(suffixes)-1:\n",
    "        nbytes /= 1024.\n",
    "        i += 1\n",
    "    f = ('%.2f' % nbytes).rstrip('0').rstrip('.')\n",
    "    return '%s %s' % (f, suffixes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Order of operations:\n",
    "Normalize each column so that each row value of a column uses up\n",
    "the same number of bytes.\n",
    "Read the expanded CSV file and identify the seek locations for each line.\n",
    "\"\"\"\n",
    "# Open the file and get its size\n",
    "filename = './data/out.csv'\n",
    "size = os.path.getsize(filename)\n",
    "human_size = humansize(size)\n",
    "data = open(filename, 'r')\n",
    "\n",
    "# Get the max width of every column\n",
    "column_widths = defaultdict(int)\n",
    "pos = 0\n",
    "while pos < size:\n",
    "    line = data.readline()[:-1]\n",
    "    for i, val in enumerate(line.split(',')):\n",
    "        width = len(val)\n",
    "        if width > column_widths[i]:\n",
    "            column_widths[i] = width\n",
    "    pos = data.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'column_widths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-85cccc66b422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolumn_widths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'column_widths' is not defined"
     ]
    }
   ],
   "source": [
    "column_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa,ab,ac,ae,ad,af,aj,ah,ai,ak,al,am,an,ao,ap,aq,ar,ba,bb,bc,be,bd,bf,bj,bh,bi,bk,bl,bm,bn,bo,bp,bq,br,ca,cb,cc,ce,cd,cf,cj,ch,ci,ck,cl,cm,cn,co,cp,cq,cr,ea,eb,ec,ee,ed,ef,ej,eh,ei,ek,el,em,en,eo,ep,eq,er,da,db,dc,de,dd,df,dj,dh,di,dk,dl,dm,dn,do,dp,dq,dr,fa,fb,fc,fe,fd,ff,fj,fh,fi,fk,fl,fm,fn,fo,fp,fq,fr,ja,jb,jc,je,jd,jf,jj,jh,ji,jk,jl,jm,jn,jo,jp,jq,jr,ha,hb,hc,he,hd,hf,hj,hh,hi,hk,hl,hm,hn,ho,hp,hq,hr,ia,ib,ic,ie,id,if,ij,ih,ii,ik,il,im,in,io,ip,iq,ir,ka,kb,kc,ke,kd,kf,kj,kh,ki,kk,kl,km,kn,ko,kp,kq,kr,la,lb,lc,le,ld,lf,lj,lh,li,lk,ll,lm,ln,lo,lp,lq,lr,ma,mb,mc,me,md,mf,mj,mh,mi,mk,ml,mm,mn,mo,mp,mq,mr,na,nb,nc,ne,nd,nf,nj,nh,ni,nk,nl,nm,nn,no,np,nq,nr,oa,ob,oc,oe,od,of,oj,oh,oi,ok,ol,om,on,oo,op,oq,or,pa,pb,pc,pe,pd,pf,pj,ph,pi,pk,pl,pm,pn,po,pp,pq,pr,qa,qb,qc,qe,qd,qf,qj,qh,qi,qk,ql,qm,qn,qo,qp,qq,qr,ra,rb,rc,re,rd,rf,rj,rh,ri,rk,rl,rm,rn,ro,rp,rq,rr\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open(filename, 'r')\n",
    "data.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 GB 1.05 GB\n"
     ]
    }
   ],
   "source": [
    "# Write the values out to max width\n",
    "exp_filename = \"./data/exp_out.csv\"\n",
    "exp_data = open(exp_filename, 'w')\n",
    "data.seek(0)\n",
    "exp_data.write(data.readline())\n",
    "pos = data.tell()\n",
    "while pos < size:\n",
    "    line = data.readline()[:-1]\n",
    "    new_vals = [val.rjust(column_widths[i]) for i, val in enumerate(line.split(','))]\n",
    "    exp_data.write(','.join(new_vals)+'\\n')\n",
    "    pos = data.tell()\n",
    "\n",
    "data.close()\n",
    "exp_data.close()\n",
    "\n",
    "exp_size = os.path.getsize(exp_filename)\n",
    "exp_human_size = humansize(size)\n",
    "print(human_size, exp_human_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_filename = \"./data/exp_out.csv\"\n",
    "\n",
    "exp_df = pd.read_csv(exp_filename, nrows=10)\n",
    "exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_filename = \"./data/exp_out.csv\"\n",
    "f = open(exp_filename, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa,ab,ac,ae,ad,af,aj,ah,ai,ak,al,am,an,ao,ap,aq,ar,ba,bb,bc,be,bd,bf,bj,bh,bi,bk,bl,bm,bn,bo,bp,bq,br,ca,cb,cc,ce,cd,cf,cj,ch,ci,ck,cl,cm,cn,co,cp,cq,cr,ea,eb,ec,ee,ed,ef,ej,eh,ei,ek,el,em,en,eo,ep,eq,er,da,db,dc,de,dd,df,dj,dh,di,dk,dl,dm,dn,do,dp,dq,dr,fa,fb,fc,fe,fd,ff,fj,fh,fi,fk,fl,fm,fn,fo,fp,fq,fr,ja,jb,jc,je,jd,jf,jj,jh,ji,jk,jl,jm,jn,jo,jp,jq,jr,ha,hb,hc,he,hd,hf,hj,hh,hi,hk,hl,hm,hn,ho,hp,hq,hr,ia,ib,ic,ie,id,if,ij,ih,ii,ik,il,im,in,io,ip,iq,ir,ka,kb,kc,ke,kd,kf,kj,kh,ki,kk,kl,km,kn,ko,kp,kq,kr,la,lb,lc,le,ld,lf,lj,lh,li,lk,ll,lm,ln,lo,lp,lq,lr,ma,mb,mc,me,md,mf,mj,mh,mi,mk,ml,mm,mn,mo,mp,mq,mr,na,nb,nc,ne,nd,nf,nj,nh,ni,nk,nl,nm,nn,no,np,nq,nr,oa,ob,oc,oe,od,of,oj,oh,oi,ok,ol,om,on,oo,op,oq,or,pa,pb,pc,pe,pd,pf,pj,ph,pi,pk,pl,pm,pn,po,pp,pq,pr,qa,qb,qc,qe,qd,qf,qj,qh,qi,qk,ql,qm,qn,qo,qp,qq,qr,ra,rb,rc,re,rd,rf,rj,rh,ri,rk,rl,rm,rn,ro,rp,rq,rr\\n 125, 782, 253,  60, 414, 972, 297, 471, 609, 835, 467, 548,  99, 340, 625, 805, 710, 903, 185, 955, 915, 292, 299,  14, 501, 640, 82'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1, 991, 123,  19,  56, 132, 580, 811,  56, 771, 164, 362, 733, 188, 979, 721,  68, 363, 574, 148, 749, 609, 797, 811, 835, 334, 406, 264,  72,  50, 898, 468,  10, 160,  46, 149, 312, 612, 504, 757, 628, 417, 721, 240, 890, 627, 431, 245, 430, 578, 427, 363, 416, 416, 852, 444, 254, 181, 522, 689, 814, 699, 101, 115, 134, 291, 171, 763, 317, 873, 402, 618, 327, 676, 371, 933, 237, 585, 729, 414, 575, 338,  69, 673, 492, 150, 867, 535, 940, 572,  49, 231, 165, 541, 773, 215, 896, 795, 297, 777, 436, 640,  66, 113, 105, 102, 284, 231, 426,  81, 338, 335,  47, 228, 341, 374, 538, 588, 876, 581, 686, 584,  74, 377, 703, 758, 583, 513, 477, 618, 569, 634, 943, 449, 998, 650, 397, 896, 415, 762, 378, 895, 400, 511, 614, 368, 954, 518, 966, 794, 266, 349, 927, 185, 416, 686, 359, 864, 951, 165, 196, 610, 238, 739, 961, 413, 566, 336, 662,  27, 785, 695, 327, 325, 669, 680, 574, 664,  30, 396,   9, 421, 565, 253, 537, 523,  40,  21, 479, 596, 400, 827, 211, 815, 793, 557,  16, 118, 573,  71, 63'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method for returning rows\n",
    "def rows_by_index(rows, filename):\n",
    "    rows = sorted(rows)\n",
    "    c = 0\n",
    "    f = open(filename, 'r')\n",
    "    tmp_file = './tmp'\n",
    "    o = open(tmp_file, 'w')\n",
    "    o.write(f.readline() + '\\n')\n",
    "    for i in rows:\n",
    "        while c < i:\n",
    "            f.readline()\n",
    "        o.write(f.readline()+'\\n')\n",
    "    o.close()\n",
    "    f.close()\n",
    "    ret_val = pd.read_csv(tmp_file)\n",
    "    os.remove(tmp_file)\n",
    "    return ret_val\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "class FixedWidth:\n",
    "    \"\"\"\n",
    "    Normalizes the columns of the input csv to fixed widths\n",
    "    Traverses rows and columns efficiently using seek and read\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_csv, tmp_dir):\n",
    "        \"\"\"\n",
    "        The input_csv is normalized and written to output_csv\n",
    "        \"\"\"\n",
    "        self.input_csv = input_csv\n",
    "        self.tmp_dir = tmp_dir\n",
    "        self.input_size = os.path.getsize(input_csv)\n",
    "        self.widths = self.get_widths()\n",
    "        \n",
    "    def get_widths(self):\n",
    "        \"\"\"\n",
    "        Finds the maximum width for each column in the input_csv.\n",
    "        \"\"\"\n",
    "        # Print the amount of time it takes to find or read the widths\n",
    "        start_time = time.time()\n",
    "        end_time = 0\n",
    "        widths = defaultdict(int)\n",
    "        \n",
    "        # Load the widths from a tmp pickle file \n",
    "        widths_pickle = self.tmp_dir + 'widths.pickle'\n",
    "        if os.path.exists(widths_pickle):\n",
    "            with open(widths_pickle, 'rb') as f:\n",
    "                widths = pickle.load(f)\n",
    "            end_time = time.time()\n",
    "        else:\n",
    "            # Read the widths off of the input csv\n",
    "            widths = self.read_widths()\n",
    "                    \n",
    "            # Done reading widths\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Save the widths for another run\n",
    "            if not os.path.exists(self.tmp_dir):\n",
    "                os.makedirs(self.tmp_dir)\n",
    "            with open(widths_pickle, 'wb') as f:\n",
    "                pickle.dump(widths, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        print(\"Got widths in %.2f seconds\" % (end_time - start_time,))\n",
    "        return widths\n",
    "    \n",
    "    def read_widths(self):\n",
    "        # Use multiple processes to read the file\n",
    "        processes = 5\n",
    "        manager = mp.Manager()\n",
    "        queue = manager.Queue()\n",
    "        pool = mp.Pool(processes=processes)\n",
    "        \n",
    "        # Start a listener to consume output from the workers\n",
    "        listener = pool.apply_async(FixedWidth.widths_consumer, (queue,))\n",
    "        \n",
    "        # Start workers to read chunks of the input_csv\n",
    "        jobs = []\n",
    "        rows = self.input_size / ((processes - 1) * 2)\n",
    "        print(\"Splitting %d bytes between 4 processes in chunks of %d\" % (self.input_size, rows))\n",
    "        for i in range(8):\n",
    "            start_pos = i * rows\n",
    "            end_pos = start_pos + rows\n",
    "            if end_pos > self.input_size:\n",
    "                end_pos = self.input_size\n",
    "            args = (queue, self.input_csv, start_pos, end_pos)\n",
    "            job = pool.apply_async(FixedWidth.widths_producer, args)\n",
    "            jobs.append(job)\n",
    "                \n",
    "        # Wait for jobs to finish\n",
    "        for job in jobs:\n",
    "            job.get()\n",
    "        \n",
    "        # Notify listener to stop listening and receive aggegrate from listener\n",
    "        queue.put(-1)\n",
    "        widths = listener.get()\n",
    "        \n",
    "        # Clean up\n",
    "        pool.close()\n",
    "        return widths\n",
    "    \n",
    "    @staticmethod\n",
    "    def widths_producer(queue, csv, start_pos, end_pos):\n",
    "        print(\"Reading widths from %d to %d\" % (start_pos, end_pos))\n",
    "        with open(csv, 'r') as f:\n",
    "            position = f.seek(start_pos)\n",
    "            widths = defaultdict(int)\n",
    "            while position < end_pos:\n",
    "                # Read a line from the csv without \\n\n",
    "                line = f.readline()[:-1]\n",
    "\n",
    "                # Record the maximum length by column index\n",
    "                for i, val in enumerate(line.split(',')):\n",
    "                    width = len(val)\n",
    "                    if width > widths[i]:\n",
    "                        widths[i] = width\n",
    "\n",
    "                # Update the position in the file\n",
    "                position = f.tell()\n",
    "        queue.put(widths)\n",
    "        return widths\n",
    "    \n",
    "    @staticmethod\n",
    "    def widths_consumer(queue):\n",
    "        widths = defaultdict(int)\n",
    "        stop = False\n",
    "        while not queue.empty() or  not stop:\n",
    "            chunk_widths = queue.get()\n",
    "            if chunk_widths == -1:\n",
    "                stop = True\n",
    "            else:\n",
    "                for k in chunk_widths:\n",
    "                    if chunk_widths[k] > widths[k]:\n",
    "                        widths[k] = chunk_widths[k]\n",
    "        return widths\n",
    "            \n",
    "    \n",
    "    def write(self, output_csv):\n",
    "        # Record running time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Read from the input csv and write to new fixed width csv\n",
    "        in_file = open(self.input_csv, 'r')\n",
    "        out_file = open(output_csv, 'w')\n",
    "        \n",
    "        # Write the column headers\n",
    "        out_file.write(in_file.readline())\n",
    "        \n",
    "        # Write each line with justified values\n",
    "        position = in_file.tell()\n",
    "        while position < self.input_size:\n",
    "            line = in_file.readline()[:-1].split(',')\n",
    "            fixed = [v.rjust(self.widths[i]) for i, v in enumerate(line)]\n",
    "            position += out_file.write(','.join(fixed)+'\\n')\n",
    "        \n",
    "        # Close the files\n",
    "        in_file.close()\n",
    "        out_file.close()\n",
    "        \n",
    "        # Print run time\n",
    "        end_time = time.time()\n",
    "        print(\"Wrote fixed width csv in %.2f seconds\" % (end_time - start_time,))\n",
    "        \n",
    "    def column_operation(self, csv, first_column, second_column, operation):\n",
    "        \"\"\"\n",
    "        Performs a WHERE comparison over the columns of the csv\n",
    "        \n",
    "        \"FROM out.csv WHERE asdf < fdsa\" \n",
    "        column_operation(\"out.csv\", \"asdf\", \"fdsa\", Operators.LessThan)\n",
    "        \n",
    "        param: csv: csv file to query\n",
    "        param: first_column: column name as string\n",
    "        param: second_column: column name as string\n",
    "        param: operation: comparison to make over values\n",
    "        \"\"\"\n",
    "        # Record the running time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Use multiple processes to read the file\n",
    "        processes = 5\n",
    "        manager = mp.Manager()\n",
    "        queue = manager.Queue()\n",
    "        pool = mp.Pool(processes=processes)\n",
    "        \n",
    "        # Look up the starting position and width of the columns in a row\n",
    "        col1 = 0\n",
    "        col1_width = 0\n",
    "        col2 = 0\n",
    "        col2_width = 0\n",
    "        line_length = 0\n",
    "        f = open(csv, 'r')\n",
    "        column_line = f.readline()\n",
    "        columns = column_line[:-1].split(',')\n",
    "        f.close()\n",
    "        for i, k in enumerate(columns):\n",
    "            inc = self.widths[i]\n",
    "            if k == first_column:\n",
    "                col1 = line_length\n",
    "                col1_width = inc\n",
    "            elif k == second_column:\n",
    "                col2 = line_length\n",
    "                col2_width = inc\n",
    "            line_length += inc + 1\n",
    "        assert(1445 == line_length)\n",
    "            \n",
    "        # Start a listener aggregate results\n",
    "        listener = pool.apply_async(FixedWidth.operation_aggregator, (queue, csv))\n",
    "        \n",
    "        # Start jobs to compare column values\n",
    "        start = len(column_line)\n",
    "        fixed_size = os.path.getsize(csv) - start\n",
    "        lines = fixed_size / line_length\n",
    "        chunks = 8\n",
    "        chunksize = (lines // chunks) * line_length\n",
    "        jobs = []\n",
    "        for i in range(1,chunks):\n",
    "            start_pos = chunksize * i + start\n",
    "            end_pos = start_pos + chunksize\n",
    "            if i == chunks - 1:\n",
    "                end_pos = fixed_size\n",
    "            args = (queue, csv, start_pos, end_pos, col1, col1_width, col2, col2_width, line_length)\n",
    "            j = pool.apply_async(FixedWidth.operation_comparator, args)\n",
    "            jobs.append(j)\n",
    "                \n",
    "        # Wait for jobs to finish\n",
    "        for job in jobs:\n",
    "            job.get()\n",
    "        \n",
    "        # Notify listener to stop listening and receive aggegrate from listener\n",
    "        queue.put(-1)\n",
    "        rows = listener.get()\n",
    "        \n",
    "        # Clean up\n",
    "        pool.close()\n",
    "        \n",
    "        # Print the running time\n",
    "        end_time = time.time()\n",
    "        print('Performed operation in %.3f seconds' % (end_time - start_time,))\n",
    "        return rows\n",
    "    \n",
    "    @staticmethod\n",
    "    def operation_aggregator(queue, csv):\n",
    "        lines = []\n",
    "        stop = False\n",
    "        f = open(csv, 'r')\n",
    "        while not queue.empty() or not stop:\n",
    "            row_byte_index = queue.get()\n",
    "            if row_byte_index == -1:\n",
    "                stop = True\n",
    "            else:\n",
    "                for index in row_byte_index:\n",
    "                    f.seek(index)\n",
    "                    lines.append(f.readline()[:10])\n",
    "        f.close()\n",
    "        return lines\n",
    "    \n",
    "    @staticmethod\n",
    "    def operation_comparator(queue, csv, start_pos, end_pos, col1, col1_width, col2, col2_width, line_length):\n",
    "        print(\"Comparing from %d to %d\" % (start_pos, end_pos))\n",
    "        \n",
    "        # Make sure that the first column is actually first\n",
    "        if col2 < col1:\n",
    "            col1, col2 = col2, col1\n",
    "            col1_width, col2_width = col2_width, col1_width\n",
    "\n",
    "        # Seek through the columns\n",
    "        results = []\n",
    "        with open(csv, 'r') as f:\n",
    "            position = f.seek(start_pos)\n",
    "            while position < end_pos:\n",
    "                f.seek(position + col1)\n",
    "                v1 = int(f.read(col1_width))\n",
    "                f.seek(position + col2)\n",
    "                v2 = int(f.read(col2_width))\n",
    "                if v1 == v2:\n",
    "                    results.append(position)\n",
    "                position = f.seek(position + line_length)\n",
    "            f.close()\n",
    "        \n",
    "        queue.put(results)\n",
    "        return results\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading widths from 140674598 to 281349196\n",
      "Reading widths from 0 to 140674598\n",
      "Reading widths from 281349196 to 422023794\n",
      "Reading widths from 422023794 to 562698392\n",
      "Splitting 1125396785 bytes between 4 processes in chunks of 140674598\n",
      "Reading widths from 562698392 to 703372990\n",
      "Reading widths from 703372990 to 844047588\n",
      "Reading widths from 844047588 to 984722186\n",
      "Reading widths from 984722186 to 1125396785\n",
      "Got widths in 41.73 seconds\n"
     ]
    }
   ],
   "source": [
    "# Read the widths from scratch\n",
    "if os.path.exists('./data/tmp/widths.pickle'):\n",
    "    os.remove('./data/tmp/widths.pickle')\n",
    "csv = FixedWidth('./data/out.csv', './data/tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(csv.widths.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got widths in 0.00 seconds\n",
      "Wrote fixed width csv in 102.19 seconds\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./data/fixed_out.csv'):\n",
    "    os.remove('./data/fixed_out.csv')\n",
    "csv = FixedWidth('./data/out.csv', './data/tmp/')\n",
    "csv.write('./data/fixed_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 142, 359,', '  42, 994,', ' 672, 466,', ' 457, 504,']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('./data/fixed_out.csv')\n",
    "\n",
    "f.seek(70336242)\n",
    "lines = [f.readline()[:10], f.readline()[:10], f.readline()[:10], f.readline()[:10]]\n",
    "f.close()\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('./data/fixed_out.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa,ab,ac,ae,ad,af,aj,ah,ai,ak,al,am,an,ao,ap,aq,ar,ba,bb,bc,be,bd,bf,bj,bh,bi,bk,bl,bm,bn,bo,bp,bq,br,ca,cb,cc,ce,cd,cf,cj,ch,ci,ck,cl,cm,cn,co,cp,cq,cr,ea,eb,ec,ee,ed,ef,ej,eh,ei,ek,el,em,en,eo,ep,eq,er,da,db,dc,de,dd,df,dj,dh,di,dk,dl,dm,dn,do,dp,dq,dr,fa,fb,fc,fe,fd,ff,fj,fh,fi,fk,fl,fm,fn,fo,fp,fq,fr,ja,jb,jc,je,jd,jf,jj,jh,ji,jk,jl,jm,jn,jo,jp,jq,jr,ha,hb,hc,he,hd,hf,hj,hh,hi,hk,hl,hm,hn,ho,hp,hq,hr,ia,ib,ic,ie,id,if,ij,ih,ii,ik,il,im,in,io,ip,iq,ir,ka,kb,kc,ke,kd,kf,kj,kh,ki,kk,kl,km,kn,ko,kp,kq,kr,la,lb,lc,le,ld,lf,lj,lh,li,lk,ll,lm,ln,lo,lp,lq,lr,ma,mb,mc,me,md,mf,mj,mh,mi,mk,ml,mm,mn,mo,mp,mq,mr,na,nb,nc,ne,nd,nf,nj,nh,ni,nk,nl,nm,nn,no,np,nq,nr,oa,ob,oc,oe,od,of,oj,oh,oi,ok,ol,om,on,oo,op,oq,or,pa,pb,pc,pe,pd,pf,pj,ph,pi,pk,pl,pm,pn,po,pp,pq,pr,qa,qb,qc,qe,qd,qf,qj,qh,qi,qk,ql,qm,qn,qo,qp,qq,qr,ra,rb,rc,re,rd,rf,rj,rh,ri,rk,rl,rm,rn,ro,rp,rq,rr\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.tell()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125396345 1445 778821.0 48676.3125 70337271.5625\n"
     ]
    }
   ],
   "source": [
    "f.seek(0)\n",
    "l = len(f.readline())\n",
    "l1 = len(f.readline())\n",
    "size = os.path.getsize('./data/fixed_out.csv') - l\n",
    "rows = size / length\n",
    "print(size, l1, size / l1, rows / 16, rows / 16 * l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9, 955, 492, 101,  36, 592, 878, 781, 184, 263, 615, 866, 263, 628, 600, 555, 190, 848, 485, 517,  67, 392, 278, 943, 315, 155, 921, 233, 505, 437, 661, 900, 214, 999,  43, 560, 128, 309, 994, 555, 734, 192, 404, 770, 198, 928, 415, 686, 649, 144, 894, 324, 811,  93, 985, 785, 439,  40,  98,  77, 221,  18, 574, 134, 920, 369, 965, 138, 378, 703, 879, 296, 576, 223, 316, 721,   3, 513, 374, 168, 672, 430, 978, 871, 173, 601, 264, 777, 488, 945, 321,  78, 507,  48, 850, 636, 407, 696,  91, 621, 724, 338, 719, 403, 154,  28,  61, 596, 546,  88, 819, 111, 640, 262, 617, 690, 516, 845, 796, 405, 401, 191, 357, 688, 940, 371, 941, 996, 315, 534, 425, 778, 902, 473, 665, 244, 877, 585, 825, 616, 998, 995, 582, 639, 936, 498,   7, 181, 864,   4, 260, 384,  96, 789, 827, 829, 546, 458, 110, 874, 293, 869, 227,  64, 443,1001, 981, 300, 173, 154, 608,   3, 812, 887\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(70336820)\n",
    "s = f.readline()\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70336242 70336242\n"
     ]
    }
   ],
   "source": [
    "f.seek(0)\n",
    "s = 0\n",
    "for i in range(rows // 16):\n",
    "    s += len(f.readline())\n",
    "print(s, f.tell())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4396015.125\n"
     ]
    }
   ],
   "source": [
    "print(70336242 / 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 142, 359, 818, 369, 351, 962, 804, 122, 629,  57, 734, 772, 244, 336, 297,  94, 291, 914, 349, 254, 947, 858, 119, 249, 675, 390, 493, 982, 875, 891, 824, 426, 529, 756, 620,  55, 805, 923, 835, 171, 257, 171, 961, 901, 515, 513, 725,  97, 773, 548,   4, 741, 578, 961, 627, 936, 449, 663, 935, 137, 474, 541, 467, 830, 953, 951, 770, 678, 175, 580, 748, 314, 792, 939, 416, 769, 638, 838, 644, 785,  31, 769, 990,  18, 194, 629, 742, 753, 149, 564, 790, 582,  39, 934, 119, 135, 620, 369, 254, 845, 393, 153, 756, 582, 838, 491, 314,  55, 407, 463, 844, 894, 163,  74, 311, 369, 955, 492, 101,  36, 592, 878, 781, 184, 263, 615, 866, 263, 628, 600, 555, 190, 848, 485, 517,  67, 392, 278, 943, 315, 155, 921, 233, 505, 437, 661, 900, 214, 999,  43, 560, 128, 309, 994, 555, 734, 192, 404, 770, 198, 928, 415, 686, 649, 144, 894, 324, 811,  93, 985, 785, 439,  40,  98,  77, 221,  18, 574, 134, 920, 369, 965, 138, 378, 703, 879, 296, 576, 223, 316, 721,   3, 513, 374, 168, 672, 430, 978, 871, 173, 601, 264, 777, 488, 945, 321,  78, 507,  48, 850, 636, 407, 696,  91, 621, 724, 338, 719, 403, 154,  28,  61, 596, 546,  88, 819, 111, 640, 262, 617, 690, 516, 845, 796, 405, 401, 191, 357, 688, 940, 371, 941, 996, 315, 534, 425, 778, 902, 473, 665, 244, 877, 585, 825, 616, 998, 995, 582, 639, 936, 498,   7, 181, 864,   4, 260, 384,  96, 789, 827, 829, 546, 458, 110, 874, 293, 869, 227,  64, 443,1001, 981, 300, 173, 154, 608,   3, 812, 887\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '123'\n",
    "b = ' 234'.strip()\n",
    "a < b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got widths in 0.00 seconds\n",
      "Comparing from 140674507 to 281348147\n",
      "Comparing from 281348147 to 422021787\n",
      "Comparing from 562695427 to 703369067\n",
      "Comparing from 422021787 to 562695427\n",
      "Comparing from 703369067 to 844042707\n",
      "Comparing from 844042707 to 984716347\n",
      "Comparing from 984716347 to 1125396345\n",
      "Performed operation in 8.469 seconds\n"
     ]
    }
   ],
   "source": [
    "csv = FixedWidth('./data/out.csv', './data/tmp/')\n",
    "results = csv.column_operation('./data/fixed_out.csv', 'aa', 'ab', '=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
